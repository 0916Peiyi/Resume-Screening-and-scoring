{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368d4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pdf to txt\n",
    "import PyPDF2\n",
    "def ConvertPdf(i):\n",
    "    pdfFileObj= open(i[1],'rb')\n",
    "    pdfReader= PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    num_pages=pdfReader.numPages\n",
    "    count=0\n",
    "    text=\"\"\n",
    "    while count<num_pages:\n",
    "        pageObj=pdfReader.getPage(count)\n",
    "        count+=1\n",
    "        text+=pageObj.extractText()\n",
    "        text=text.replace('\\n',' ')\n",
    "        text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcc58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert word to txt\n",
    "import textract\n",
    "def ConvertWord(i):\n",
    "    wordtext=textract.process(i[1])\n",
    "    wordtext=wordtext.replace(b'\\n',b'')\n",
    "    wordtext=wordtext.replace(b'\\r',b'')\n",
    "    wordtext=wordtext.replace(b'\\t',b'')\n",
    "    text1=str(wordtext)\n",
    "    text1=text1.lower()\n",
    "    return text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7baf722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is LIST OF FILES\n",
      "['PWC_Olivia Peter_Regulatory Manager.pdf', 'PWC_Penny Lim_Risk AM.pdf', 'Jam.docx']\n",
      "######## PARSING #########\n",
      "This is pdf\n",
      "This is pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is word file\n",
      "###### DONE PARSING ######\n"
     ]
    }
   ],
   "source": [
    "## judge pdf/word+ connect\n",
    "import os\n",
    "import glob\n",
    "\n",
    "    \n",
    "list_of_files=[]\n",
    "list_of_files_pdf=[]\n",
    "list_of_files_doc=[]\n",
    "list_of_files_docx=[]\n",
    "resumes=[]\n",
    "os.chdir('C:/Users/DELL-LH2018/Desktop/intern/All original resume')\n",
    "for file in glob.glob('**/*.pdf',recursive=True):\n",
    "    list_of_files_pdf.append(file)\n",
    "for file in glob.glob('**/*.doc',recursive=True):\n",
    "    list_of_files_doc.append(file)\n",
    "for file in glob.glob('**/*.docx',recursive=True):\n",
    "    list_of_files_docx.append(file)\n",
    "list_of_files = list_of_files_pdf+list_of_files_doc+list_of_files_docx\n",
    "print(\"This is LIST OF FILES\")\n",
    "print(list_of_files)\n",
    "    \n",
    "#convert\n",
    "print(\"######## PARSING #########\")\n",
    "for i in enumerate(list_of_files):\n",
    "    Temp= i[1].split(\".\")\n",
    "    if Temp[1]==\"pdf\" or Temp[1]==\"Pdf\" or Temp[1]==\"PDF\":\n",
    "        print(\"This is pdf\")   \n",
    "        ConvertPdf(i)\n",
    "        resumes.extend([ConvertPdf(i)])\n",
    "    if Temp[1]==\"doc\" or Temp[1]==\"Doc\" or Temp[1]==\"DOC\" or Temp[1]==\"docx\" or Temp[1]==\"Docx\" or Temp[1]==\"DOCX\":\n",
    "        print(\"This is word file\")\n",
    "        ConvertWord(i)\n",
    "        resumes.extend([ConvertWord(i)])\n",
    "print(\"###### DONE PARSING ######\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7fa8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>education</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>risk</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jam</td>\n",
       "      <td>DS</td>\n",
       "      <td>assurance</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>governance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>regulatory compliance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>integrity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>general ledger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>media</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>sales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Jam</td>\n",
       "      <td>General</td>\n",
       "      <td>small claims</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Candidate Name  Subject                 Keyword Count\n",
       "0              Jam  General              education      4\n",
       "1              Jam  General                   risk      5\n",
       "2              Jam       DS              assurance      5\n",
       "3              Jam  General             governance      1\n",
       "4              Jam  General  regulatory compliance      1\n",
       "..             ...      ...                     ...   ...\n",
       "124            Jam  General              integrity      1\n",
       "125            Jam  General         general ledger      1\n",
       "126            Jam  General                  media      1\n",
       "127            Jam  General                  sales      1\n",
       "128            Jam  General           small claims      1\n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keywords\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "def KeywordsFilter(j):\n",
    "    keyword_dict=pd.read_excel('C:/Users/DELL-LH2018/Desktop/intern/Job skills.xlsx',sheet_name='data scientist',header=None,names=['keywords of ds'])\n",
    "    keyword_dict1=pd.read_excel('C:/Users/DELL-LH2018/Desktop/intern/Job skills.xlsx',sheet_name='general skills',header=None,names=['keywords of gs'])\n",
    "    data_scientist_words=[nlp(text) for text in keyword_dict['keywords of ds'].dropna(axis = 0)]\n",
    "    general_skill_words=[nlp(text) for text in keyword_dict1['keywords of gs'].dropna(axis = 0)]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('DS',None,*data_scientist_words)\n",
    "    matcher.add('General',None,*general_skill_words)\n",
    "    doc=nlp(j)\n",
    "    d=[]\n",
    "    matches=matcher(doc)\n",
    "    filtered_matches=[]\n",
    "    for m in sorted(matches,key=lambda m:(m[1],-m[2])):\n",
    "        if not filtered_matches or (m[1]>=filtered_matches[-1][-1] or m[2]>filtered_matches[-1][-1]):\n",
    "            filtered_matches.append(m)\n",
    "            filtered_matches\n",
    "    for match_id, start, end in filtered_matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]\n",
    "        span = doc[start : end]\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{a[0]} {a[1]} ({b})' for a,b in Counter(d).items())\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    name = Temp[0]\n",
    "    cname = pd.read_csv(StringIO(name),names = ['Candidate Name'])\n",
    "    dataf = pd.concat([cname['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    return dataf\n",
    "\n",
    "KeywordsFilter(str(resumes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2362f24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jam</td>\n",
       "      <td>Experience</td>\n",
       "      <td>analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jam</td>\n",
       "      <td>Experience</td>\n",
       "      <td>business analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jam</td>\n",
       "      <td>Experience</td>\n",
       "      <td>finance analyst</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Candidate Name     Subject            Keyword Count\n",
       "0            Jam  Experience           analyst      1\n",
       "1            Jam  Experience  business analyst      1\n",
       "2            Jam  Experience   finance analyst      2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experience\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "def ExperienceFilter(k):\n",
    "    keyword_dict2=pd.read_excel('C:/Users/DELL-LH2018/Desktop/intern/Job skills.xlsx',sheet_name='experience',header=None,names=['keywords of exp'])\n",
    "    experience_words=[nlp(text) for text in keyword_dict2['keywords of exp'].dropna(axis = 0)]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Experience',None,*experience_words)\n",
    "    doc=nlp(k)\n",
    "    d=[]\n",
    "    matches=matcher(doc)\n",
    "    filtered_matches=[]\n",
    "    for m in sorted(matches,key=lambda m:(m[1],-m[2])):\n",
    "        if not filtered_matches or (m[1]>=filtered_matches[-1][-1] or m[2]>filtered_matches[-1][-1]):\n",
    "            filtered_matches.append(m)\n",
    "            filtered_matches\n",
    "    for match_id, start, end in filtered_matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]\n",
    "        span = doc[start : end]\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{a[0]} {a[1]} ({b})' for a,b in Counter(d).items())\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    name = Temp[0]\n",
    "    cname = pd.read_csv(StringIO(name),names = ['Candidate Name'])\n",
    "    datae = pd.concat([cname['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    datae['Candidate Name'].fillna(datae['Candidate Name'].iloc[0], inplace = True)\n",
    "    return datae\n",
    "\n",
    "ExperienceFilter(str(resumes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faeb356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Python\", \"Pythonect\", \"Python 1.5\", \"Python 2.4\", \"Python/C API\", \"Python HOWTOs\", \"PythonAnywhere\", \"Python Debugger\", \"Python Robotics\", \"Python Compilers\"]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skill API:\n",
    "import requests\n",
    "\n",
    "url = \"https://api.promptapi.com/skills?q=python\"\n",
    "payload = {}\n",
    "headers= {\n",
    "  \"apikey\": \"PRC9IcUURAUQL9qAvywXoJTUVztfsHRp\"\n",
    "}\n",
    "response = requests.request(\"GET\", url, headers=headers,data =payload)\n",
    "status_code = response.status_code\n",
    "result = response.text\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a732ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight of every keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f0890c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is LIST OF FILES\n",
      "['PWC_Olivia Peter_Regulatory Manager.pdf', 'PWC_Penny Lim_Risk AM.pdf', 'Jam.docx']\n",
      "######## PARSING #########\n",
      "This is pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Candidate Name  Subject     Keyword Count\n",
      "0  PWC_Olivia Peter_Regulatory Manager  General  education      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Candidate Name Subject Keyword Count\n",
      "0  PWC_Olivia Peter_Regulatory Manager     NaN     NaN   NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total score of PWC_Olivia Peter_Regulatory Manager is 0.5 + 0.0\n",
      "This is pdf\n",
      "           Candidate Name  Subject                 Keyword Count\n",
      "0   PWC_Penny Lim_Risk AM  General                   risk      5\n",
      "1   PWC_Penny Lim_Risk AM       DS              assurance      5\n",
      "2   PWC_Penny Lim_Risk AM  General             governance      1\n",
      "3   PWC_Penny Lim_Risk AM  General  regulatory compliance      1\n",
      "4   PWC_Penny Lim_Risk AM  General             compliance      3\n",
      "..                    ...      ...                     ...   ...\n",
      "69  PWC_Penny Lim_Risk AM  General          business case      1\n",
      "70  PWC_Penny Lim_Risk AM  General                written      1\n",
      "71  PWC_Penny Lim_Risk AM  General               mandarin      1\n",
      "72  PWC_Penny Lim_Risk AM  General                    llc      1\n",
      "73  PWC_Penny Lim_Risk AM  General          mental health      1\n",
      "\n",
      "[74 rows x 4 columns]\n",
      "          Candidate Name     Subject   Keyword Count\n",
      "0  PWC_Penny Lim_Risk AM  Experience  analyst      1\n",
      "The total score of PWC_Penny Lim_Risk AM is 37.0 + 1\n",
      "This is word file\n",
      "   Candidate Name  Subject          Keyword Count\n",
      "0             Jam  General         us gaap      1\n",
      "1             Jam  General            ifrs      1\n",
      "2             Jam  General    great plains      1\n",
      "3             Jam       DS             sql      1\n",
      "4             Jam  General             fit      1\n",
      "..            ...      ...              ...   ...\n",
      "66            Jam  General       integrity      1\n",
      "67            Jam  General  general ledger      1\n",
      "68            Jam  General           media      1\n",
      "69            Jam  General           sales      1\n",
      "70            Jam  General    small claims      1\n",
      "\n",
      "[71 rows x 4 columns]\n",
      "  Candidate Name     Subject            Keyword Count\n",
      "0            Jam  Experience  business analyst      1\n",
      "1            Jam  Experience   finance analyst      2\n",
      "The total score of Jam is 35.5 + 3\n",
      "###### DONE PARSING ######\n"
     ]
    }
   ],
   "source": [
    "#whole\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "list_of_files=[]\n",
    "list_of_files_pdf=[]\n",
    "list_of_files_doc=[]\n",
    "list_of_files_docx=[]\n",
    "resumes=[]\n",
    "os.chdir('C:/Users/DELL-LH2018/Desktop/intern/All original resume')\n",
    "for file in glob.glob('**/*.pdf',recursive=True):\n",
    "    list_of_files_pdf.append(file)\n",
    "for file in glob.glob('**/*.doc',recursive=True):\n",
    "    list_of_files_doc.append(file)\n",
    "for file in glob.glob('**/*.docx',recursive=True):\n",
    "    list_of_files_docx.append(file)\n",
    "list_of_files = list_of_files_pdf+list_of_files_doc+list_of_files_docx\n",
    "print(\"This is LIST OF FILES\")\n",
    "print(list_of_files)\n",
    "    \n",
    "#convert\n",
    "print(\"######## PARSING #########\")\n",
    "for i in enumerate(list_of_files):\n",
    "    Temp= i[1].split(\".\")\n",
    "    if Temp[1]==\"pdf\" or Temp[1]==\"Pdf\" or Temp[1]==\"PDF\":\n",
    "        print(\"This is pdf\")   \n",
    "        print(KeywordsFilter(ConvertPdf(i)))\n",
    "        print(ExperienceFilter(ConvertPdf(i)))\n",
    "        \n",
    "        kw=KeywordsFilter(ConvertPdf(i))\n",
    "        sum1=np.sum(kw['Subject'] == 'DS')\n",
    "        sum2=np.sum(kw['Subject'] == 'General')\n",
    "        score1=0.5*sum1+0.5*sum2\n",
    "        exp=ExperienceFilter(ConvertPdf(i))\n",
    "        exp['Count']=pd.to_numeric(exp['Count'],errors='coerce')\n",
    "        score2=np.sum(exp['Count'])\n",
    "        print(\"The total score of\",Temp[0],\"is\",score1,\"+\",score2)\n",
    "    \n",
    "        resumes.extend([ConvertPdf(i)])\n",
    "    if Temp[1]==\"doc\" or Temp[1]==\"Doc\" or Temp[1]==\"DOC\" or Temp[1]==\"docx\" or Temp[1]==\"Docx\" or Temp[1]==\"DOCX\":\n",
    "        print(\"This is word file\")\n",
    "        print(KeywordsFilter(ConvertWord(i)))\n",
    "        print(ExperienceFilter(ConvertWord(i)))\n",
    "        \n",
    "        kw=KeywordsFilter(ConvertWord(i))\n",
    "        sum1=np.sum(kw['Subject'] == 'DS')\n",
    "        sum2=np.sum(kw['Subject'] == 'General')\n",
    "        score1=0.5*sum1+0.5*sum2\n",
    "        exp=ExperienceFilter(ConvertWord(i))\n",
    "        exp['Count']=pd.to_numeric(exp['Count'],errors='coerce')\n",
    "        score2=np.sum(exp['Count'])\n",
    "        print(\"The total score of\",Temp[0],\"is\",score1,\"+\",score2)\n",
    "        \n",
    "        resumes.extend([ConvertWord(i)])\n",
    "print(\"###### DONE PARSING ######\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec0a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: 9171\n",
      "Found match: 6979\n",
      "Found match: 2014\n",
      "Found match: 2012\n",
      "Found match: 2014\n",
      "Found match: 2011\n",
      "Found match: 2012\n",
      "Found match: 2011\n",
      "Found match: 2011\n",
      "Found match: 2010\n",
      "Found match: 2010\n",
      "Found match: 2015\n",
      "Found match: 2008\n",
      "Found match: 2012\n",
      "Found match: 2010\n",
      "Found match: 2010\n",
      "Found match: 2012\n",
      "Found match: 2012\n",
      "Found match: 2010\n",
      "Found match: 2009\n",
      "Found match: 2009\n",
      "Found match: 2012\n",
      "Found match: 2009\n",
      "Found match: 2011\n",
      "Found match: 2008\n",
      "Found match: 2008\n",
      "Found match: 2007\n",
      "Found match: 2007\n",
      "Found match: 2015\n",
      "Found match: 2013\n",
      "Found match: 2014\n",
      "Found match: 2015\n",
      "Found match: 2011\n",
      "Found match: 2016\n",
      "Found match: 2016\n",
      "Found match: 2016\n",
      "Found match: 2010\n",
      "Found match: 2013\n",
      "Found match: 2013\n",
      "Found match: 2008\n",
      "Found match: 2008\n",
      "Found match: 2005\n"
     ]
    }
   ],
   "source": [
    "#date\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(str(resumes))\n",
    "\n",
    "expression = (r'(?P<year>\\d\\d\\d\\d)'\n",
    "                 r'(?:(?P<dsep>-|)'\n",
    "                 r'(?:(?P<julian>\\d\\d\\d)'\n",
    "                 r'|(?P<month>\\d\\d)(?:(?P=dsep)(?P<day>\\d\\d))?))?')\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0b0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
